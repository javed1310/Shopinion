# Shopinion
This project is an interactive web application that performs sentiment analysis on product reviews. It not only predicts the sentiment (Positive, Negative, or Neutral) but also provides explanations for its predictions using SHAP (SHapley Additive exPlanations), making the model's decisions transparent and understandable.

The application is built with Python, using a fine-tuned Transformer model for sequence classification and Streamlit for the user interface.


# ‚ú® FEATURES
Interactive Web Interface: A user-friendly web app built with Streamlit to analyze review text in real-time.

Accurate Sentiment Prediction: Utilizes a fine-tuned Transformer model to classify text into Positive, Negative, and Neutral categories.

Explainable AI (XAI): Integrates SHAP to generate waterfall plots, visualizing which words contributed most to each sentiment prediction.

Easy to Set Up: A requirements.txt file is included for a straightforward setup process.

# üöÄ How It Works
The project follows a standard machine learning pipeline:

Data Preparation: The sentiment analysis model was trained on a dataset of product reviews (found in s24_reviews_labeled_vader.csv and CLEANED_REVIEWS_NO_DUPLICATES.csv).

Model Training: The ReviewSentimentalAnalysis.ipynb notebook contains the complete workflow for data cleaning, preprocessing, and fine-tuning a Transformer model for sentiment classification.

Inference and Explanation: The fine-tuned model and tokenizer are saved and then served by a Streamlit application (app.py).

Web Application: When a user enters a review, the app's backend performs inference.

Visualization: The predicted sentiment is displayed, and SHAP generates visualizations to explain the reasoning behind the prediction.

# üõ†Ô∏è Installation & Setup
Follow these steps to set up and run the project on your local machine.

Prerequisites
Python 3.8 or higher

pip package manager

1. Clone the Repository
git clone [https://github.com/javed1310/Shopinion.git](https://github.com/javed1310/Shopinion.git)
cd your-repository-name

2. Create a Virtual Environment (Recommended)
It's best practice to create a virtual environment to manage project dependencies.

# For Windows
python -m venv venv
venv\Scripts\activate

# For macOS/Linux
python3 -m venv venv
source venv/bin/activate

3. Install Dependencies
Install all the required Python libraries using the requirements.txt file.

pip install -r requirements.txt

4. Train the Model (or Use a Pre-trained One)
The core model files are not included in this repository. You must generate them by running the Jupyter Notebook.

# Launch Jupyter Notebook:

jupyter notebook

Open and run all the cells in ReviewSentimentalAnalysis.ipynb. This will train the model and save the necessary files (model directory and label_encoder.pkl).

Important: Make sure the notebook saves the model and the label encoder to a known location. You may need to update the paths in app.py to point to where these files are saved. For simplicity, you can create a model directory in the root of the project and save the assets there.

# ‚ñ∂Ô∏è How to Run the Application
Once the setup is complete and the model files are in place, you can start the Streamlit web application.

Run the app.py file using Streamlit:

streamlit run app.py

Your web browser should automatically open a new tab with the application running.

Enter a product review into the text box and click the "Analyze Sentiment" button to see the prediction and its explanation.

# üìÇ File Structure
Here is an overview of the key files in this project:

app.py: The main Python script for the Streamlit web application.

ReviewSentimentalAnalysis.ipynb: Jupyter Notebook containing the end-to-end process of data cleaning, model training, and evaluation.

requirements.txt: A list of all Python dependencies required to run the project.

label_encoder.pkl: A saved scikit-learn LabelEncoder object used to map sentiment labels to integers. (Generated by the notebook).

/model/: A directory containing the fine-tuned Transformer model and its tokenizer. (Generated by the notebook).

*.csv: CSV files containing the datasets used for training and testing the model.

# üîß Technologies Used
Programming Language: Python

Web Framework: Streamlit

ML/DL Libraries: PyTorch, Transformers (Hugging Face), scikit-learn

XAI Library: SHAP

Data Manipulation: Pandas

Development Environment: Jupyter Notebook

# ü§ù Contributing
Contributions, issues, and feature requests are welcome!.
